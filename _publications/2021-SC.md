---
title: "Efficient Tensor Core-based GPU Kernels for Structured Sparsity under Reduced Precision"
collection: publications
permalink: /publication/2021-SC
excerpt: 'Accelerate structured sparsity under reduced precision and small granularity with Tensor Core'
date: 2020-6-22
venue: 'The International Conference for High Performance Computing, Networking, Storage, and Analysis (SC) 2021'
paperurl: 'https://seal.ece.ucsb.edu/sites/default/files/publications/vector_sparse_transformer_camera_ready_.pdf'
citation: 'Zhaodong Chen, Zheng Qu, Liu Liu, Yufei Ding, and Yuan Xie. "Efficient Tensor Core-based GPU Kernels for Structured Sparsity under Reduced Precision." 2021 Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis.'
---
We propose column-vector-sparse-encoding that has a smaller grain size under the same reuse rate compared with block sparsity. Column-vector-sparse-encoding can be applied to both SpMM & SDDMM, two major sparse DNN operations. We also introduce the Tensor-Core-based 1D Octet Tiling that has efficient memory access and computation patterns under small grain size. Based on these, we design SpMM and SDDMM kernels and achieve 1.71-7.19x speedup over cuSPARSE. Practical speedup is achieved over cuBLASHgemm under >70% and >90% sparsity with 4x1 grain size and half-precision.

```
@article{chen2021efficient,
  title={Efficient Tensor Core-based GPU Kernels for Structured Sparsity under Reduced Precision},
  author={Chen, Zhaodong and Qu, Zheng and Liu, Liu and Ding, Yufei and Xie, Yuan},
  journal={The International Conference for High Performance Computing, Networking, Storage, and Analysis},
  volume={},
  number={},
  pages={},
  year={2021},
  publisher={}
}
```
